{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Summaries\n",
    "\n",
    "Define call to summarizer and summary assembler.\n",
    "\n",
    "## Summary assembler\n",
    "\n",
    "Summarizer returns list of segment index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_assembler(results, corpus, nb_words, over_window = 0) :\n",
    "    \"\"\"\n",
    "    Build the summary of a document with the result of the summarizer.\n",
    "    \n",
    "    Given the score for each sentences, selectes the top <nb_words> sentences\n",
    "    to build a summary.\n",
    "    \n",
    "    \n",
    "    :param results:     List of score per sentence in the document.\n",
    "                        Higher score denote a higher importance of the sentence.\n",
    "    :param corpus:      Dictionary mapping a document key to document content.\n",
    "    :param nb_words:    Number of words in the final summary.\n",
    "    :param over_window: The number of words to add from a sentences.\n",
    "                        The window over wich words are added to form a ngram.\n",
    "    \n",
    "    :return:   A list of sentences id picked as the top sentences for the summary.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the id of the sentences, ie, its position in the related document.\n",
    "    list_sent_id = [item[0] for item in sorted(enumerate(results), key=lambda x: x[1], reverse = True)]\n",
    "    \n",
    "    stops = set(stopwords.words('french'))\n",
    "    \n",
    "    # List of id forming the summary.\n",
    "    summary_sent_id = []\n",
    "    \n",
    "    if over_window:\n",
    "        words = set()\n",
    "        for sent_id in list_sent_id:\n",
    "            summary_sent_id.append(sent_id)\n",
    "            # ???\n",
    "            for word_id in range(sent_id * over_window, sent_id * over_window + len(corpus[sent_id].split())):\n",
    "                words.add(word_id)\n",
    "            if len(words) >= nb_words:\n",
    "                break\n",
    "    else:\n",
    "        for sent_id in list_sent_id:\n",
    "            summary_sent_id.append(sent_id)\n",
    "            if len( \" \".join([ \" \".join(set(corpus[i].split())-stops) for i in summary_sent_id]).split() ) >= nb_words:\n",
    "                break\n",
    "    return sorted(summary_sent_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_and_cut_at(sentence_list, limit, stops):\n",
    "    \"\"\"\n",
    "    Generate a sentence of fiwed length while cleaning stop words.\n",
    "    \n",
    "    :param sentence_list:    List of sentence to process.\n",
    "    :param limit:            Size of sentences.\n",
    "    :param stop:             Set of stop words.\n",
    "    \"\"\"\n",
    "    return \" \".join(\" \".join([\" \".join(set(s.split())-stops) for s in sentence_list]).split()[:limit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing the summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def wrapper(doc_key, summarizer, all_args) :\n",
    "    \"\"\"\n",
    "    Wrapper over the summarize method of the summarizers.\n",
    "    Passes arguments to the summarizer during multi-processing.\n",
    "    \n",
    "    :param doc_key:    Key of the document : document set id + document id.\n",
    "    \n",
    "    :returns:    A tuple : (doc_key summary_sent_id)\n",
    "                     doc_key: docset id + doc id\n",
    "                     summary_sent_id: list of sentences index of the document\n",
    "                     forming the summary for the given document.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # all_args[0] <=> preprocessed sentences of the document.\n",
    "    return (doc_key, summary_assembler(summarizer.summarize(all_args[0], all_args[-1]), *all_args[:-1]))\n",
    " \n",
    "\n",
    "def doc_summarizer(docs, summarizer, nb_words, over_window, docs_bias = None):\n",
    "    \"\"\"\n",
    "    Dispatch over a pool the summarization.\n",
    "    Each worker runs for a document (doc_key) a summary of\n",
    "    the document content (sents[1]) - array of cleaned sentences.\n",
    "    \n",
    "    \n",
    "    :param docs:           Tokenized corpus. Array of (???).\n",
    "    :param summarizer:     Summarizer process. See Summary_Processes directory.\n",
    "    :param nb_words:       Length of the summary, ie, the nb of word forming it.\n",
    "    :param over_window:    ???\n",
    "    :param docs_bias:      Dictionnay mapping to a document key its vocabulary bias\n",
    "                           (ie, biased weight for words in the document)\n",
    "    \n",
    "    :return:    A dictionnay of predicted summaries.\n",
    "                Maps a document key (docset + doc id) to a list of\n",
    "                sentences index of the document forming the summary.\n",
    "    \"\"\"\n",
    "    ## INIT ##\n",
    "    summary = {}\n",
    "    \n",
    "    \n",
    "    with Pool(20) as p:\n",
    "        list_summary = p.starmap(wrapper, [(doc_key , summarizer, (sents, nb_words, over_window, docs_bias[doc_key] if docs_bias is not None else None)) \n",
    "                  for doc_key, sents in docs.items()]) #sents[1] for other datasets\n",
    "    \n",
    "    summary = {k : s for k,s in list_summary}\n",
    "    \n",
    "    return summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
