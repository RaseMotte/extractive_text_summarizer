{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextRank TFIDF\n",
    "\n",
    "### Basics\n",
    "* $|document| = n$\n",
    "* $|vocab| = m$\n",
    "\n",
    "### TfIdf\n",
    "* $X$ : tfidf matrix $n \\times m$\n",
    "* $s_i$: one row of the matrix, vector representation of a sentence with tfidf weights.\n",
    "The vector is $L_2$ normalized, ie, $\\|s_i\\|^2 = 1$\n",
    "\n",
    "### Cosinus similarity or cosine Kernel $\\mathbf{K}$ \n",
    "\n",
    "$\\mathbf{K}(X, X) = \\large \\frac{<X, X>}{\\|X\\|\\times \\|X\\|} = \\frac{X.X^T}{\\|X\\|^2} = \\frac{X.X^T}{\\sum_{i=1}^n \\sum_{j=1}^n x_{ij}^2}$\n",
    "\n",
    "$\\Longleftrightarrow K(X, X) =$$\\large \\frac{1}{\\sum_{i=1}^n \\|s_i\\|2}$$ \\times\n",
    "\\begin{pmatrix}\n",
    "s_1 \\\\\n",
    "... \\\\\n",
    "s_n \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "s_1 & ... & s_n \n",
    "\\end{pmatrix}$\n",
    "\n",
    "$\\Longleftrightarrow K(X, X) =$$\\large \\frac{1}{\\sum_{i=1}^n \\|s_i\\|2}$$ \\times\n",
    "\\begin{pmatrix}\n",
    "<s_1, s_1> & ... & <s_1, s_n>\\\\\n",
    "... \\\\\n",
    "<s_n, s_1> & ... & <s_n, s_n>\n",
    "\\end{pmatrix}$ we know that $\\|s_i\\|^2 = 1$\n",
    "\n",
    "$\\Longleftrightarrow K(X, X) =$$\\large \\frac{1}{n}$$ \\times\n",
    "\\begin{pmatrix}\n",
    "<s_1, s_1> & ... & <s_1, s_n>\\\\\n",
    "... \\\\\n",
    "<s_n, s_1> & ... & <s_n, s_n>\n",
    "\\end{pmatrix}$\n",
    "\n",
    "$K(X, X)$ defines a Gram matrix, representing the distance between each sentences in the futur space.\n",
    "It can be seen as the correlation of 2 sentences over the vocabulary.\n",
    "\n",
    "This Gram matrix represent our adjancy matrix. Each cell represent an edge (weighted) between two sentences.\n",
    "\n",
    "### weakening matrix (ok, pas sûre que ça se traduise comme ça)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "import inspect\n",
    "import seaborn \n",
    "%run Summary_Processes/Generic_Summarizer.ipynb\n",
    "\n",
    "class TextRank_TFIDF_Summarizer_Assym_process :\n",
    "    def __init__(self, a, b, weighted=False, method=\"tr\", lsanbcompfun = None, diag = \"none\",  tag = None, bias = None) :\n",
    "        \n",
    "        self.weighted = weighted\n",
    "        self.method = method\n",
    "        self.lsanbcompfun = lsanbcompfun\n",
    "        self.diag = diag\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        self.bias = bias\n",
    "        \n",
    "        methodstr = \"TextRank\" if method == \"tr\" else \"LSA\"\n",
    "        weightedstr = \"weighted\" if weighted else \"unweighted\"\n",
    "        self.__name__ = ( methodstr + \"_TFIDF_Summarizer_Assym_process(\" + str(self.a) + \",\"\n",
    "                         + str(self.b) + \",\" + weightedstr+ \",\"\n",
    "                         + diag + \", \" + str(bias) + \" )\" + ((\"-\" + tag) if tag is not None else \"\"))\n",
    "        \n",
    "    def preprocess(self, corpus):\n",
    "        \"\"\"\n",
    "        Builds the idf matrix with all sentence tokens of the corpus.\n",
    "        Also builds the vocabulary of the vocabulary of the corpus.\n",
    "        It's a dictionay mapping a word to its feature indice (index).\n",
    "        \n",
    "        :param corpus:  Array of strings. Each string is a sentence token.\n",
    "                        The whole dataset is flatten, document are not separated.\n",
    "        \"\"\"\n",
    "        # Learn our representation space, ie, its dimension (vocabulary size)\n",
    "        # and the idf factors.\n",
    "        self.vectorizer.fit(corpus)\n",
    "\n",
    "    def summarize(self, corpus, doc_biais=None):\n",
    "        \"\"\"\n",
    "        :param corpus:  One document from the corpus. Array of string.\n",
    "                        Each string is a sentence token.\n",
    "                        \n",
    "        :return:    ????\n",
    "        \"\"\"\n",
    "        # Transform the document in a vector representation.\n",
    "        X = self.vectorizer.transform(corpus)\n",
    "        \n",
    "        # Calcul de la matrice d'affaiblissement des lien entre les phrases les plus éloignées\n",
    "        dist = np.array([np.arange(X.shape[0]) - i for i in range(0, X.shape[0])])\n",
    "        pos = dist > 0\n",
    "        neg = dist < 0\n",
    "        factor = (np.power(self.a, np.abs(np.multiply(dist,pos)))\n",
    "                  + np.power(self.b, np.abs(np.multiply(dist,neg)))\n",
    "                  - 1)\n",
    "        \n",
    "        # Build the similarity matrix defining distance between sentences with cosinus similarity.\n",
    "        # Apply the \"weakening\" matrix on the result.\n",
    "        matrix = np.multiply(factor, cos_sim(X, X))\n",
    "        \n",
    "        # Use of a generic method which calls the correct method\n",
    "        return generic_summarizer(self.method, matrix, corpus, self.weighted, self.lsanbcompfun, diag =  self.diag, bias = self.bias)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__name__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
