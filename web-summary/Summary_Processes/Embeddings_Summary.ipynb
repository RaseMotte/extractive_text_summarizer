{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim\n",
    "import sklearn\n",
    "import inspect\n",
    "%run Summary_Processes/Generic_Summarizer.ipynb\n",
    "from math import log\n",
    "import numpy as np\n",
    "import seaborn\n",
    "from collections import defaultdict\n",
    "class Embeddings_process :\n",
    "    \n",
    "    def __init__(self, path_to_embeddings, path_to_words, counts, nb_docs, eigen_folder, direct_file = None, \n",
    "                 factor = -0.25, transpose1 = False, transpose2 = False, a = 1.0, b = 0.1, weighted = True,\n",
    "                exponentiation = 0, method = \"tr\", lsanbcompfun = None, tag = None,diag = \"none\", bias = 0) :\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.weighted = weighted\n",
    "        self.exponentiation = exponentiation\n",
    "        self.method = method\n",
    "        self.lsanbcompfun = lsanbcompfun\n",
    "        self.diag = diag\n",
    "        self.bias = bias\n",
    "        methodstr = \"TextRank\" if method == \"tr\" else \"LSA\"\n",
    "        if inspect.isroutine(lsanbcompfun):\n",
    "            source = inspect.getsource(lsanbcompfun).replace(\"\\n\",\"\")\n",
    "            funcstr = re.sub(r'^.*lsanbcompfun *= *([^,\\)]+)[,\\)]+.*$',r'\\1',source) if \"lsanbcompfun\" in source else \"-\"\n",
    "        else:\n",
    "            funcstr = \"-\"\n",
    "        self.__name__ = (methodstr + \"_Embeddings(\" + str(factor) + \",\" \n",
    "                         + str(transpose1) + \",\" + str(transpose2) + \",\"\n",
    "                         + str(a) + \",\" + str(b) + \",\"\n",
    "                         + (\"weighted\" if weighted else \"unweighted\") + \",\"\n",
    "                         + \"exp\"+str(exponentiation) + \",\" \n",
    "                         + funcstr\n",
    "                         +\",\"+diag+\",\"+str(bias)\n",
    "                         + \")\" + ((\"-\" + tag) if tag is not None else \"\"))\n",
    "        self.factor = factor\n",
    "        wordlist = []\n",
    "        with open(eigen_folder+path_to_words) as file :\n",
    "            line = file.readline()\n",
    "            while line :\n",
    "                wordlist.append(line[:-1])\n",
    "                line = file.readline()\n",
    "        print(\"Words done\")\n",
    "\n",
    "        if direct_file :\n",
    "            emb =  np.load(eigen_folder+direct_file)\n",
    "        else :\n",
    "            \n",
    "            matrix = np.genfromtxt(eigen_folder+\"eigen-vectors.csv\", delimiter = \",\")\n",
    "            values = np.genfromtxt(eigen_folder+\"eigen-values.csv\", delimiter = \",\")\n",
    "            values = np.diag(values**(self.factor))\n",
    "            if transpose1:\n",
    "                matrix = matrix.T\n",
    "            self.transit = np.matmul(values, matrix)\n",
    "            if transpose2:\n",
    "                self.transit = self.transit.T\n",
    "            self.dim = matrix.shape[0]\n",
    "            print(\"Transit done\")\n",
    "\n",
    "            with open(eigen_folder+nb_docs) as file :\n",
    "                nb_doc = int(file.readline())\n",
    "            print(\"NB done\")\n",
    "\n",
    "            ct = {}\n",
    "            with open(eigen_folder+counts) as file :\n",
    "                line = file.readline()\n",
    "                while line :\n",
    "                    data_line = line[:-1].split(\",\")\n",
    "                    ct[data_line[0]] = [int(data_line[1])]\n",
    "                    line = file.readline()\n",
    "            ct_order = []\n",
    "            for word in wordlist :\n",
    "                ct_order.append(ct[word])\n",
    "            print(\"Counts done\")\n",
    "\n",
    "            emb = np.load(eigen_folder+path_to_embeddings)\n",
    "            print(\"Embeddings loaded\")\n",
    "            self.idf = np.log(nb_doc/np.array(ct_order))\n",
    "            emb *= self.idf\n",
    "            self.maxidf = np.max(self.idf)\n",
    "            #np.save(eigen_folder+\"embeddings_docs-pit.npy\", emb)\n",
    "            print(\"Embeddings transformed\")\n",
    "\n",
    "        self.embed = {}\n",
    "        for i, word in enumerate(wordlist) :\n",
    "            self.embed[word] = emb[i]\n",
    "\n",
    "        print(\"Embeddings done\")\n",
    "       \n",
    "        \n",
    "        self.voc = set(self.embed.keys())\n",
    "        self.D = len(emb[0])\n",
    "        # TF-IDF of sentence(1,V) * embedings(V,D) * eigen(D, ?)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def preprocess(self, corpus, docs_bias=None):\n",
    "        pass\n",
    "\n",
    "    def summarize(self,corpus, docs_bias=None) :\n",
    "        X = self.represent(corpus)\n",
    "        dist = np.array([np.arange(X.shape[0]) - i for i in range(0,X.shape[0])])\n",
    "        pos = dist > 0\n",
    "        neg = dist < 0\n",
    "        assymfactor = (np.power(self.a, np.abs(np.multiply(dist,pos))) \n",
    "                       + np.power(self.b, np.abs(np.multiply(dist,neg))) \n",
    "                       - 1)\n",
    "        sim_base = cos_sim(X,X)\n",
    "        for i in range(self.exponentiation):\n",
    "            sim_base = np.expm1(sim_base)\n",
    "            sim_base = sim_base / np.max(sim_base)\n",
    "        matrix = np.multiply(assymfactor,sim_base)\n",
    "        \n",
    "        return generic_summarizer(self.method, matrix, corpus, self.weighted, self.lsanbcompfun, diag =  self.diag, bias = self.bias)\n",
    "\n",
    "    def represent(self,corpus, apply_ortho = True) :\n",
    "        X = []\n",
    "        unknown = 0\n",
    "        for sen in corpus :\n",
    "            v = np.zeros(self.D)\n",
    "            wc = defaultdict(int)\n",
    "            for word in sen.split() :\n",
    "                wc[word]+=1.0\n",
    "            for word in wc :\n",
    "                if word in  self.voc :\n",
    "                    v += self.embed[word] * wc[word]**0.75\n",
    "                else:\n",
    "                    np.random.seed(hash(word) & (2**32-1))\n",
    "                    tmpv = np.random.randn(self.dim)\n",
    "                    tmpv = tmpv / np.linalg.norm(tmpv)\n",
    "                    v += self.maxidf * tmpv * wc[word]**0.75\n",
    "                    unknown += 1\n",
    "            if apply_ortho:\n",
    "                v = np.matmul(self.transit,v)\n",
    "            X.append(v)\n",
    "        X = np.array(X)\n",
    "\n",
    "        return(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
