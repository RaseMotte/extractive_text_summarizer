{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn import decomposition\n",
    "import seaborn\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(A, eps=0.0001, d=0.85, max_iter = 5000):\n",
    "    \"\"\"\n",
    "    PageRank algorithm.\n",
    "    \n",
    "    Given a similarity matrix, returns list of score for each sentence.\n",
    "\n",
    "    :param A:         matrix (n, n)\n",
    "                      The adjacency matrix of the graph on which to compute PageRank score\n",
    "                      \n",
    "    :param eps:       float, optional\n",
    "                      Tolerance. The algorithm stops as soon as the update magnitude of all\n",
    "                      values is below this threshold.\n",
    "              \n",
    "    :param d:         float, optional\n",
    "                      1 - probability of teleporting to a random node\n",
    "            \n",
    "    :param max_iter:  int, optional\n",
    "                      Maximum number of iterations\n",
    "                      \n",
    "    :return:    A matrix (n, n).\n",
    "                The ranking of sentences in the document.\n",
    "    \"\"\"\n",
    "    \n",
    "    # P is the vector of probability to \"teleport\" on each node. By default filled of 1/n.\n",
    "    P = np.ones(len(A)) / len(A)\n",
    "    \n",
    "    while max_iter > 0 :\n",
    "        max_iter-=1\n",
    "        # Markov chain transition\n",
    "        new_P = np.ones(len(A)) * (1 - d) / len(A) + d * A.dot(P)\n",
    "        # Normalization\n",
    "        new_P = new_P / np.linalg.norm(new_P)\n",
    "        # Compute mean absolute error (MAE)\n",
    "        delta = abs(new_P - P).sum() / len(new_P)\n",
    "        if delta <= eps:\n",
    "            return new_P\n",
    "        P = new_P\n",
    "    \n",
    "    print(\"Convergence error : \" + str(delta))\n",
    "    return new_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_summarizer(matrix, corpus, weights=None, nb_words = 100, diag = \"none\", bias = 0):\n",
    "    \"\"\"\n",
    "    Prepare the sentence-term matrix before applying PageTank algorithm to it.\n",
    "    \n",
    "    :param matrix:    matrix (n, m)\n",
    "                      A sentence-term matrix weighting the importance of a term for a sentence.\n",
    "                      \n",
    "    :param corpus:    list of string.\n",
    "                      A single document.\n",
    "    \n",
    "    :param weights:   ???\n",
    "    :param nb_words:  The number of words for the summary.\n",
    "    :param diag:      ???\n",
    "    :param biais:     ???\n",
    "    \"\"\"\n",
    "    \n",
    "    matrix = np.array(matrix)\n",
    "    \n",
    "    if diag == \"before\":\n",
    "         np.fill_diagonal(matrix,0)   \n",
    "    \n",
    "    sim_matrix = normalize(matrix , norm = 'l1', axis = 0)\n",
    "    \n",
    "    if (not weights is None) and (len(weights) == matrix.shape[0]):\n",
    "        sim_matrix = np.matmul(sim_matrix,np.diag(weights))\n",
    "    \n",
    "    if diag == \"after\" :\n",
    "        np.fill_diagonal(matrix,0)\n",
    "\n",
    "    sim_matrix = sim_matrix + bias / matrix.shape[0]\n",
    "    results = pagerank(sim_matrix)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa_summarizer(matrix, corpus, weights=None, nbcompfun = None, nb_words = 100, diag = \"none\", bias = 0):\n",
    "    \"\"\"\n",
    "    :param matrix:    matrix (n, m)\n",
    "                      sentence-term matrix weighting the importance of a term for a sentence.\n",
    "    \n",
    "    :param corpus:    list of string.\n",
    "                      A single document.\n",
    "    :param weights:   ???\n",
    "    :param nbcompfun: ???\n",
    "    :param nb_words:  The number of words for the summary.\n",
    "    :param diag:      ???\n",
    "    :param biais:     ???\n",
    "    \n",
    "    \"\"\"\n",
    "    #MÃ©thode de calcul LSA\n",
    "    matrix = np.array(matrix)\n",
    "    \n",
    "    if nbcompfun == None:\n",
    "        nbcompfun = lambda x : log(x)\n",
    "    \n",
    "    k = max(1, int(nbcompfun(len(corpus))))\n",
    "    \n",
    "    if k >= len(corpus):\n",
    "        return np.sum(matrix,axis=1)\n",
    "    \n",
    "    if diag == \"before\" :\n",
    "        np.fill_diagonal(matrix,0) \n",
    "    \n",
    "    sim_matrix = normalize(matrix , norm = 'l1', axis = 0)\n",
    "    \n",
    "    if (not weights is None) and (len(weights) == matrix.shape[0]):\n",
    "        sim_matrix = np.matmul(sim_matrix,np.diag(weights))\n",
    "    \n",
    "    if diag == \"after\" :\n",
    "        np.fill_diagonal(matrix,0)\n",
    "    sim_matrix = sim_matrix + bias / matrix.shape[0]\n",
    "\n",
    "    #tsvd = sklearn.decomposition.TruncatedSVD(k, random_state=1337)\n",
    "    tsvd = sklearn.decomposition.TruncatedSVD(k, random_state=1337, algorithm = \"arpack\")\n",
    "    # Dimension reduction of sim_matrix using truncated SVD.\n",
    "\n",
    "    # results = topic-sentence matrix\n",
    "    results = tsvd.fit_transform(sim_matrix)\n",
    "    # scores = sigular_values @ result.T\n",
    "    # scores matrix describe how much a a sentence represent a word, thus\n",
    "    # the weight / importance of a word in a sentence.\n",
    "    scores = np.abs(np.matmul(results, np.diag(np.sqrt(tsvd.singular_values_))))\n",
    "    # Give a score per sentence as the sum of the weights of the words it contains\n",
    "    # score_sent = sum(row)\n",
    "    # REMARK : Text Summarization Techniques: A Brief survey (paper) suggest sqrt(sum(scores_ij^2))\n",
    "    maxscores = np.sum(scores,axis=1)\n",
    "\n",
    "    return maxscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_summarizer(method, matrix, corpus, weighted, lsanbcompfun = lambda x : log(x), diag = \"none\", bias = 0) :\n",
    "    #Is used to determine which method has to be used\n",
    "    if not lsanbcompfun : \n",
    "        lsanbcompfun = lambda x : 1\n",
    "    if method == \"tr\":\n",
    "            if weighted:\n",
    "                return tr_summarizer(matrix, corpus, get_weights(corpus), diag = diag, bias = bias)\n",
    "            else:\n",
    "                return tr_summarizer(matrix, corpus, diag = diag, bias = bias)\n",
    "    else:\n",
    "        if method == \"lsa\":\n",
    "            if weighted:\n",
    "                return lsa_summarizer(matrix, corpus, get_weights(corpus),\n",
    "                                      nbcompfun = lsanbcompfun, diag = diag , bias = bias)\n",
    "            else:\n",
    "                return lsa_summarizer(matrix, corpus, nbcompfun = lsanbcompfun, diag = diag, bias = bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(corpus):\n",
    "    weights = []\n",
    "    nbsent = len(corpus)\n",
    "    sentindex=nbsent+1\n",
    "    for sent in corpus :\n",
    "        splitsent = sent.split()\n",
    "        weights.append(len(splitsent) / ((sentindex**0.5)))\n",
    "        sentindex -= 1.0        \n",
    "    weights = np.array(weights)\n",
    "    weights = nbsent*weights/np.sum(weights)\n",
    "    return weights  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
